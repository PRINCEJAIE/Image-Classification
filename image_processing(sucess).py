# -*- coding: utf-8 -*-
"""Image_Processing(sucess).ipynb

Automatically generated by Colab.


### **YouTube Link**

https://youtu.be/011ngYQ5TaM
"""

!pip install datasets transformers huggingface_hub torch torchvision evaluate # downloading essential packages for running this
!apt-get install git-lfs

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import models, transforms
from sklearn.metrics import accuracy_score, f1_score
from transformers import ViTImageProcessor, ViTForImageClassification
from PIL import Image
import pandas as pd
import numpy as np
import random

def set_seed(seed: int = 100):
    random.seed(seed)                  # Python random module
    np.random.seed(seed)                # Numpy
    torch.manual_seed(seed)             # PyTorch
    torch.cuda.manual_seed_all(seed)    # GPU-based randomness
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(100)

train_dir = "/content/drive/MyDrive/DogvsCats/dogs-vs-cats-vvsmall/train" # assigning variables
val_dir = "/content/drive/MyDrive/DogvsCats/dogs-vs-cats-vvsmall/validation" # assigning variables

class CatDogDataset(Dataset): # creating a custom dataset using pytorch through inheritance based of https://stackoverflow.com/questions/51677788/data-augmentation-in-pytorch
    def __init__(self, root_dir, transform=None): # including the transform allows for data augmentation and preprocessing
      self.root_dir = root_dir # stores the provided root to self
      self.transform = transform #stores the rpvided transfromation funciton
      self.image_paths = [] # empty list to store the file paths
      self.labels = [] # empty list for all the label

      for label, class_name in enumerate(["cats", "dogs"]): # this is a beefed up version of label_ mapping using a for loop based off of https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats/
        class_dir = os.path.join(root_dir, class_name) # basically creating a full path of each class
        for image_name in os.listdir(class_dir):
          image_path = os.path.join(class_dir, image_name) # creates a path to each individual image path
          self.image_paths.append(image_path)
          self.labels.append(label) # gives the images a numbered value between 0 and 1 (cats = 0, dogs = 1 )

    def __len__(self):
      return len(self.image_paths) # returns the length of the image_path

    def __getitem__(self, idx): # helps retrieve a smaple for the dataset
      image_path = self.image_paths[idx] # gets the filepath
      label = self.labels[idx] # retireves the related  label to it

      image = Image.open(image_path).convert("RGB") # converts the picture to rgb using PIL
      if self.transform:
        image = self.transform(image) # making a condition that if a transfromation fucntion is possible apply it to the pillow image

      return image,label # retun the processed image its is numeric label

train_transform = transforms.Compose([
    transforms.Resize((224, 224)), # got this from Applied AI task
    transforms.RandomHorizontalFlip(), # flipping images
    transforms.RandomRotation(15), # rotating the images in any direction with a degree tolerance of 15
    transforms.ToTensor(),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# creating two different transformation processes for each folder "train" & "valid". train has more transfomration attached to it to make sure the model it learning and able to pick distinguish between cat vs dogs

train_dataset = CatDogDataset(train_dir, transform=train_transform) # the application of the transformations to each data set using the pytorch function that was created
val_dataset = CatDogDataset(val_dir, transform=val_transform)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True) # this converts the train_dataset into managable batches as well as adding shefulling. the model will recieve 32 images with their accredited labels
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False) # this ensures consistency of model evluation

model = models.resnet50(pretrained=True) # loading the pretrained ResNet50 and all is weightings, model is useful for cmputer vision and binary classification
num_ftrs = model.fc.in_features # this is the varibale assigned to acess the final connected layer
model.fc = nn.Sequential( # this code chnages the final layer by adding a new sequentinal layer
    nn.Linear(num_ftrs, 512), # two input features with an outputed neurons of 512
    nn.ReLU(), # usage of the relu function to help learn complex patterns
    nn.Dropout(0.5), # achieves dropout regularization at 50% to prevent overfitting
    nn.Linear(512, 2) # 2 = number of class we need
)

optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay= 1e-4) # lr controls the step size in each iternation. stablizing training, as well as achieving l2 regularization
criterion = nn.CrossEntropyLoss() # created off the the skelton code provided by Iain Rice

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device) #checking gpu avaibality and moves the model to the chosen device

for epoch in range(10): # setting the model to work within 10 training epochs
  model.train() # setting the modle up for training mode
  running_loss = 0.0 # this is used to keep track of the model loss while training
  for images, labels in train_loader: # a for loop inside a for loop, privdes a tensor with a batch of images and labels (line 5)
    images, labels = images.to(device), labels.to(device)
    optimizer.zero_grad() # clears the gradient of all optimised parameters
    outputs = model(images) # this is the foreward propagation
    loss = criterion(outputs, labels) #calculates the loss between model outputs and its label
    loss.backward() # this is the backward propagation for its continued and advancement in learning
    optimizer.step() # using the
    running_loss += loss.item()
  print(f"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}") # prints out average training loss for eah respective epoch

  model.eval() # chnages the model form training mode to evaluation mode
  val_preds, val_labels = [], [] # creates empty listd to store the predicitons and labels
  with torch.no_grad(): # no need for computational gradients saving memeoty and process time
    for images, labels in val_loader: # loops through to by prividing batches of validation data
      images, labels = images.to(device), labels.to(device)
      outputs = model(images)
      _, preds = torch.max(outputs, 1) # gets the predicited class
      val_preds.extend(preds.cpu().numpy()) # converts the predicted labels to numpy
      val_labels.extend(labels.cpu().numpy()) # converts the true labels to a numpy array

  acc = accuracy_score(val_labels, val_preds) # comparing the accuracy between the true labels vs the predicted labels
  f1 = f1_score(val_labels, val_preds, average="weighted") # calculates the weighted average f1 score
  print(f"Validation Accuracy: {acc}, Validation F1 Score: {f1}")

# buit of https://www.geeksforgeeks.org/train-a-deep-learning-model-with-pytorch/

torch.save(model.state_dict(), f"best_model_epoch{epoch+1}.pth") # saves the best model
